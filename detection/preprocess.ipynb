{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b90a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image,ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40019bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(img):\n",
    "    categories = np.digitize(img, bins=np.linspace(img.min(), img.max(), num=6))\n",
    "    smoothed_categories = gaussian_filter(categories, sigma=0.2)\n",
    "    print(smoothed_categories.min(), '\\t', smoothed_categories.max())\n",
    "    cat1 = np.digitize(smoothed_categories, bins=np.linspace(smoothed_categories.min(), smoothed_categories.max(), num=smoothed_categories.max()))\n",
    "    return cat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59fb9e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceImg(i,j,categories):\n",
    "    stack = [(i, j)]\n",
    "\n",
    "    while stack:\n",
    "        x, y = stack.pop()\n",
    "        # Set the current cell to 1\n",
    "        categories[x][y] = 0\n",
    "\n",
    "        # Check the 4 neighboring cells (up, down, left, right)\n",
    "        for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "            nx, ny = x + dx, y + dy\n",
    "            # Ensure we stay within bounds and process only valid cells\n",
    "            if 0 <= nx < categories.shape[0] and 0 <= ny < categories.shape[1]:\n",
    "                if  categories[nx][ny] == 1:  # Only visit cells greater than 1\n",
    "                    stack.append((nx, ny))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b0919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter1(cat1):\n",
    "    found = False\n",
    "    cat2 = gaussian_filter(cat1, sigma=0.2)\n",
    "    reduceImg(0,0,cat2)\n",
    "    return cat2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bbdece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceImg2(i,j,categories):\n",
    "    stack = [(i, j)]\n",
    "\n",
    "    while stack:\n",
    "        x, y = stack.pop()\n",
    "        # Set the current cell to 1\n",
    "        categories[x][y] = 0\n",
    "\n",
    "        # Check the 4 neighboring cells (up, down, left, right)\n",
    "        for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "            nx, ny = x + dx, y + dy\n",
    "            # Ensure we stay within bounds and process only valid cells\n",
    "            if 0 <= nx < categories.shape[0] and 0 <= ny < categories.shape[1]:\n",
    "                if categories[nx][ny] >= 2:  # Only visit cells greater than 1\n",
    "                    stack.append((nx, ny))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99652a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter2(cat2):\n",
    "    found = False\n",
    "    cat3 = cat2.copy()\n",
    "    for i in range(len(cat2)):\n",
    "        for j in range(len(cat2[i])):\n",
    "            if (cat3[i][j]>=2):\n",
    "                reduceImg2(i,j,cat3)\n",
    "                found = True\n",
    "                break\n",
    "        if found:\n",
    "            break\n",
    "    i = 0\n",
    "    f=0\n",
    "    b=0\n",
    "    while i < len(cat3):\n",
    "        if 1 in cat3[i]:\n",
    "            if f==0:\n",
    "                f=1\n",
    "        else:\n",
    "            if f==1:\n",
    "                b = 1\n",
    "        if b==1:\n",
    "            cat3[i] = np.zeros(shape=cat3[i].shape)\n",
    "        i=i+1\n",
    "    return cat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b09069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def crop_to_mask(img: np.ndarray, mask: np.ndarray, pad: int = 0):\n",
    "    \"\"\"\n",
    "    Crop `img` and `mask` to the minimal bounding box around mask>0 pixels,\n",
    "    with an optional `pad` in pixels on each side.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        The original image (H×W or H×W×C).\n",
    "    mask : np.ndarray\n",
    "        A binary mask of shape (H×W), zeros outside region of interest.\n",
    "    pad : int\n",
    "        How many extra pixels to include on each side of the box (default 0).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    img_crop : np.ndarray\n",
    "        Cropped version of `img`.\n",
    "    mask_crop : np.ndarray\n",
    "        Cropped version of `mask`.\n",
    "    \"\"\"\n",
    "    # find all nonzero mask coords\n",
    "    ys, xs = np.nonzero(mask)\n",
    "    if len(xs) == 0 or len(ys) == 0:\n",
    "        # nothing to crop—return originals\n",
    "        return img, mask\n",
    "\n",
    "    # compute bounding box\n",
    "    x0, x1 = xs.min(), xs.max()\n",
    "    y0, y1 = ys.min(), ys.max()\n",
    "\n",
    "    # apply padding, clamped to image edges\n",
    "    x0 = max(x0 - pad, 0)\n",
    "    y0 = max(y0 - pad, 0)\n",
    "    x1 = min(x1 + pad, mask.shape[1] - 1)\n",
    "    y1 = min(y1 + pad, mask.shape[0] - 1)\n",
    "\n",
    "    # slice out the ROI\n",
    "    if img.ndim == 2:\n",
    "        img_crop  = img[y0:y1+1, x0:x1+1]\n",
    "    else:\n",
    "        img_crop  = img[y0:y1+1, x0:x1+1, ...]\n",
    "    mask_crop = mask[y0:y1+1, x0:x1+1]\n",
    "\n",
    "    return img_crop, mask_crop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "515561b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessLungCT(path):\n",
    "    img = img_to_array(Image.open(path).convert('L'))\n",
    "    cat1 = categorize(img)\n",
    "    cat2 = filter1(cat1)\n",
    "    mask = np.squeeze(filter2(cat2))\n",
    "    img_crop, mask_crop = crop_to_mask(img, mask, pad=5)\n",
    "    img_crop = np.squeeze(img_crop)\n",
    "    pimg = img_crop*mask_crop\n",
    "    return pimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc0ef665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56cfb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(img):\n",
    "    categories = np.digitize(img, bins=np.linspace(img.min(), img.max(), num=6))\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "    smoothed_categories = gaussian_filter(categories, sigma=0.2)\n",
    "    cat1 = np.digitize(smoothed_categories, bins=np.linspace(smoothed_categories.min(), smoothed_categories.max(), num=4))\n",
    "    return cat1\n",
    "\n",
    "def reduceImg(i,j,categories):\n",
    "    stack = [(i, j)]\n",
    "\n",
    "    while stack:\n",
    "        x, y = stack.pop()\n",
    "        # Set the current cell to 1\n",
    "        categories[x][y] = 0\n",
    "\n",
    "        # Check the 4 neighboring cells (up, down, left, right)\n",
    "        for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "            nx, ny = x + dx, y + dy\n",
    "            # Ensure we stay within bounds and process only valid cells\n",
    "            if 0 <= nx < categories.shape[0] and 0 <= ny < categories.shape[1]:\n",
    "                if  categories[nx][ny] == 1:  # Only visit cells greater than 1\n",
    "                    stack.append((nx, ny))\n",
    "    return\n",
    "\n",
    "def filter1(cat1):\n",
    "    cat2 = gaussian_filter(cat1, sigma=0.2)\n",
    "    for i in range(len(cat1)):\n",
    "        for j in range(len(cat1[i])):\n",
    "            if (cat1[i][j]==1):\n",
    "                reduceImg(i,j,cat2)\n",
    "                break\n",
    "    return cat2\n",
    "\n",
    "def reduceImg2(i,j,categories):\n",
    "    stack = [(i, j)]\n",
    "\n",
    "    while stack:\n",
    "        x, y = stack.pop()\n",
    "        # Set the current cell to 1\n",
    "        categories[x][y] = 0\n",
    "\n",
    "        # Check the 4 neighboring cells (up, down, left, right)\n",
    "        for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "            nx, ny = x + dx, y + dy\n",
    "            # Ensure we stay within bounds and process only valid cells\n",
    "            if 0 <= nx < categories.shape[0] and 0 <= ny < categories.shape[1]:\n",
    "                if categories[nx][ny] >= 2:  # Only visit cells greater than 1\n",
    "                    stack.append((nx, ny))\n",
    "    return\n",
    "\n",
    "def filter2(cat2):\n",
    "    cat3 = cat2.copy()\n",
    "    for i in range(len(cat2)):\n",
    "        for j in range(len(cat2[i])):\n",
    "            if (cat3[i][j]>=2):\n",
    "                reduceImg2(i,j,cat3)\n",
    "                break\n",
    "    i = 0\n",
    "    f=0\n",
    "    b=0\n",
    "    while i < len(cat3):\n",
    "        if 1 in cat3[i]:\n",
    "            if f==0:\n",
    "                f=1\n",
    "        else:\n",
    "            if f==1:\n",
    "                b = 1\n",
    "        if b==1:\n",
    "            cat3[i] = np.zeros(shape=cat3[i].shape)\n",
    "        i=i+1\n",
    "    return cat3\n",
    "\n",
    "def crop_to_mask(img: np.ndarray, mask: np.ndarray, pad: int = 0):\n",
    "    \"\"\"\n",
    "    Crop `img` and `mask` to the minimal bounding box around mask>0 pixels,\n",
    "    with an optional `pad` in pixels on each side.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        The original image (H×W or H×W×C).\n",
    "    mask : np.ndarray\n",
    "        A binary mask of shape (H×W), zeros outside region of interest.\n",
    "    pad : int\n",
    "        How many extra pixels to include on each side of the box (default 0).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    img_crop : np.ndarray\n",
    "        Cropped version of `img`.\n",
    "    mask_crop : np.ndarray\n",
    "        Cropped version of `mask`.\n",
    "    \"\"\"\n",
    "    # find all nonzero mask coords\n",
    "    ys, xs = np.nonzero(mask)\n",
    "    if len(xs) == 0 or len(ys) == 0:\n",
    "        # nothing to crop—return originals\n",
    "        return img, mask\n",
    "\n",
    "    # compute bounding box\n",
    "    x0, x1 = xs.min(), xs.max()\n",
    "    y0, y1 = ys.min(), ys.max()\n",
    "\n",
    "    # apply padding, clamped to image edges\n",
    "    x0 = max(x0 - pad, 0)\n",
    "    y0 = max(y0 - pad, 0)\n",
    "    x1 = min(x1 + pad, mask.shape[1] - 1)\n",
    "    y1 = min(y1 + pad, mask.shape[0] - 1)\n",
    "\n",
    "    # slice out the ROI\n",
    "    if img.ndim == 2:\n",
    "        img_crop  = img[y0:y1+1, x0:x1+1]\n",
    "    else:\n",
    "        img_crop  = img[y0:y1+1, x0:x1+1, ...]\n",
    "    mask_crop = mask[y0:y1+1, x0:x1+1]\n",
    "\n",
    "    return img_crop, mask_crop\n",
    "\n",
    "\n",
    "def preprocessLungCT(img):\n",
    "    img = np.array(Image.open(img))\n",
    "    cat1 = categorize(img)\n",
    "    cat2 = filter1(cat1)\n",
    "    mask = filter2(cat2)\n",
    "    img_crop, mask_crop = crop_to_mask(img, mask, pad=5)\n",
    "    pimg = img_crop*mask_crop\n",
    "    return pimg\n",
    "\n",
    "# Load Pretrained Model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')  # Global average pooling\n",
    "\n",
    "# Function to Extract Features\n",
    "def extract_features(image_path):\n",
    "    pimg_array = preprocessLungCT(image_path)\n",
    "    arr = pimg_array\n",
    "    # ensure uint8\n",
    "    if arr.dtype != np.uint8:\n",
    "        # scale/clip floats or cast ints\n",
    "        arr = np.clip(arr, 0, 255).astype('uint8')\n",
    "    pil = Image.fromarray(arr, mode='L').convert('RGB')\n",
    "    img_rgb = pil.resize((224,224), resample=Image.BILINEAR)\n",
    "    img_array = img_to_array(img_rgb)\n",
    "    img_array = preprocess_input(img_array)  # Preprocess for ResNet\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    features = base_model.predict(img_array)  # Extract features\n",
    "    return features.flatten()  # Flatten to 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a6ea56d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pimg = \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mF:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mSem 6\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDSA\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mLab\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mCovid19Predictor\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mwebapp\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mstatic\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43muploads\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mcov.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m plt.imshow(pimg)\n\u001b[32m      3\u001b[39m plt.show()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 134\u001b[39m, in \u001b[36mextract_features\u001b[39m\u001b[34m(image_path)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_features\u001b[39m(image_path):\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     pimg_array = \u001b[43mpreprocessLungCT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     arr = pimg_array\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# ensure uint8\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 123\u001b[39m, in \u001b[36mpreprocessLungCT\u001b[39m\u001b[34m(img)\u001b[39m\n\u001b[32m    121\u001b[39m img = np.array(Image.open(img))\n\u001b[32m    122\u001b[39m cat1 = categorize(img)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m cat2 = \u001b[43mfilter1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m mask = filter2(cat2)\n\u001b[32m    125\u001b[39m img_crop, mask_crop = crop_to_mask(img, mask, pad=\u001b[32m5\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mfilter1\u001b[39m\u001b[34m(cat1)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(cat1)):\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(cat1[i])):\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (cat1[i][j]==\u001b[32m1\u001b[39m):\n\u001b[32m     30\u001b[39m             reduceImg(i,j,cat2)\n\u001b[32m     31\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "pimg = extract_features(r'F:\\Sem 6\\DSA\\Lab\\Covid19Predictor\\webapp\\static\\uploads\\cov.png')\n",
    "plt.imshow(pimg)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
